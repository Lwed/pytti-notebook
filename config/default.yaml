# Use VISSL config system as a model of hydra/omegaconf best practices
#  - https://github.com/facebookresearch/vissl/blob/main/vissl/config/defaults.yaml
#  - https://vissl.readthedocs.io/en/latest/hydra_config.html

defaults:
  - _self_
  - conf: ???
#  - conf: demo

#############
## Prompts ##
#############
#
# `scenes:` Descriptions of scenes you want generated, separated by `||`. 
#           Each scene can contain multiple prompts, separated by `|`.
#           Weight prompts with `description:weight`. 
#           Use "stop" prompts with `description:weight:stop`. 
#
#           ## MASKS
#           Use `description:weight_mask description` with a text prompt as `mask`. 
#           - The prompt will only be applied to areas of the image that match `mask description` according to CLIP.
#           - The prompt will only be applied to the masked (white) areas of the mask image. 
#           - Use `description:weight_[-mask]` to apply the prompt to the black areas instead.
#           Use `description:weight_[mask]` with a URL or path to an image, or a path to a .mp4 video to use as a `mask`.
#           Use `[path or url]` as a prompt to add a semantic image prompt. 
#           - This will be read by CLIP and understood as a near perfect text description of the image.
#
# # # # # # #
# Examples  #
# # # # # # # 
#
# Sequence of 4 winter scenes, two text prompts each
#   `Winter sunrise | icy landscape || Winter day | snowy skyline || Winter sunset | chilly air || Winter night | clear sky` 
#
# Attempt to draw a Martian landscape with a blue sky
#   `blue sky:10|martian landscape|red sky:-1`
#
# Using "stop" weights to try to control overfitting to prompt extremes
#   `Feathered dinosaurs|birds:1:0.87|scales:-1:-.9|text:-1:-.9`
#
# Using a weight mask to target the prompt "dragon" on regions that match "baby" 
#  `Khaleesi Daenerys Targaryen | mother of dragons | dragon:3_baby`
#
# Using an image or video file as a weight mask
#   `sunlight:3_[mask.mp4]|midnight:3_[-mask.mp4]`
#
# The same notation can be used to create semantic image prompts
#  `[artist signature.png]:-1:-.95|[https://i.redd.it/ewpeykozy7e71.png]:3|fractal clouds|hole in the sky`
#
# ###########
#
# `scene_prefix:` text prepended to the beginning of each scene.
# `scene_suffix:` text appended to the end of each scene.

scenes: ???
scene_prefix: ''
scene_suffix: ''

# `direct_image_prompts:` paths or urls of images that you want your image to look like in a literal sense, 
#                         along with `weight_mask` and `stop` values, separated by `|`.
#                         Apply masks to direct image prompts with `path or url of image:weight_path 
#                         or url of mask` For video masks it must be a path to an mp4 file.
# `init_image:`           path or url of start image. Works well for creating a central focus.
# `direct_init_weight:`   Defaults to $0$. Use the initial image as a direct image prompt.
#                         Equivalent to adding `init_image:direct_init_weight` as a `direct_image_prompt`. 
#                         Supports weights, masks, and stops.
# `semantic_init_weight:` Defaults to $0$. Defaults to $0$. Use the initial image as a semantic image prompt. #                         Equivalent to adding `[init_image]:direct_init_weight` 
#                         as a prompt to each scene in `scenes`. Supports weights, masks, and stops. 
#                         **IMPORTANT** since this is a semantic prompt, you still need to put the mask
#                         in brackets -- `[` `]` -- to denote it as a path or url, 
#                         otherwise it will be read as text instead of a file.
direct_image_prompts: ''
init_image: ''
direct_init_weight: ''
semantic_init_weight: ''

##################################

image_model: Limited Palette
vqgan_model: sflckr
animation_mode: off

##################################

width: 180
height: 112

steps_per_scene: 100
steps_per_frame: 50
interpolation_steps: 0

learning_rate: null
reset_lr_each_frame: true
seed: ${now:%f} # microsecond component of timestamp. Basically random.
cutouts: 40
cut_pow: 2
cutout_border: 0.25
border_mode: clamp

##################################

##########
# Camera #
##########

field_of_view: 60
near_plane: 1
far_plane: 10000

######################
### Induced Motion ###
######################

#  _2d and _3d only apply to those animation modes

translate_x: '0'
translate_y: '0'
translate_z_3d: '0'
rotate_3d: '[1, 0, 0, 0]'
rotate_2d: '5'
zoom_x_2d: '0'
zoom_y_2d: '0'

sampling_mode: bicubic
infill_mode: wrap
pre_animation_steps: 100
lock_camera: true

##################################

#######################
### Limited Palette ###
#######################

pixel_size: 4
smoothing_weight: 0.02
random_initial_palette: false
palette_size: 6
palettes: 9
gamma: 1
hdr_weight: 0.01
palette_normalization_weight: 0.2
show_palette: false
target_palette: ''
lock_palette: false

##############
### ffmpeg ###
##############

frames_per_second: 12

direct_stabilization_weight: ''
semantic_stabilization_weight: ''
depth_stabilization_weight: ''
edge_stabilization_weight: ''
flow_stabilization_weight: ''

#####################################
### animation_mode = Video Source ###
#####################################

video_path: ''
frame_stride: 1
reencode_each_frame: true
flow_long_term_samples: 1

############
### CLIP ###
############

ViTB32: true
ViTB16: false
RN50: false
RN50x4: false

###############
### Outputs ###
###############

file_namespace: default
allow_overwrite: false
display_every: 50
clear_every: 0
display_scale: 1
save_every: 50

backups: 0
show_graphs: false
approximate_vram_usage: false

